#!/bin/bash

# Read the list of targets from targets.txt file
targets_file="ip.txt"
targets=($(cat "$targets_file"))

# Set the batch size for targets
batch_size=1

# Set the maximum number of retries and number of threads
num_threads=500

# Split the combinations.txt file into smaller files
split -l 1000000 combinations.txt combinations_

# Create a temporary directory to store the result files
temp_dir="temp_results"
mkdir "$temp_dir"

# Iterate through targets and execute commands
for ((i=0; i<${#targets[@]}; i+=batch_size)); do
    batch_targets=("${targets[@]:i:batch_size}")

    # Run Docker process for each batch of targets
    for ((j=0; j<${#batch_targets[@]}; j++)); do
        target="${batch_targets[$j]}"

        # Iterate through the smaller combination files
        for combinations_file in combinations_*; do
            command="docker run -it --rm -v $(pwd):/data secsi/ffuf -u '$target' -w /data/$combinations_file -timeout 60 -mc 200 -t $num_threads --ignore-body -sf -c -v -o '/data/$temp_dir/result_$((i+j+1)).txt'"
            eval "$command"
        done
    done

    # Wait for all processes to finish
    wait
done

# Merge temporary result files into the final results file
cat "$temp_dir"/*.txt >> final_results.txt

# Filter the results to include only status 200 and size greater than 20 bytes, and save them to a separate file
filtered_results_file="filtered_results.txt"
grep -E '.{20,}' final_results.txt | jq -r '.results[] | select(.status == 200) | .url' > "$filtered_results_file"

# Remove the temporary directory and files
rm -r "$temp_dir"
rm combinations_*

echo "Download completed!"
echo "Mohammad Elnwajha!"
